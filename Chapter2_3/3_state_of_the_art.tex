\section{Pretrained Models and Their Applications}

Pre-trained language models have seen remarkable advancements, leveraging large datasets and sophisticated training methodologies to achieve significant improvements in various natural language processing (NLP) tasks. Pre-trained models such as BERT, GPT, and their variants have revolutionized the field by providing robust, general-purpose representations that can be fine-tuned for specific tasks with minimal additional training data \cite{chen-etal-2022-bert2bert}. Techniques like function-preserving initialization and advanced knowledge initialization in Bert2BERT exemplify innovative methods to enhance the efficiency of pre-training larger models by reusing smaller pre-trained models, reducing computational costs and carbon footprints associated with training from scratch \cite{chen-etal-2022-bert2bert}.

\subsection{Applications in Specialized Fields}
The application of pre-trained models in domains such as clinical information extraction has demonstrated their versatility and effectiveness. For instance, large language models like GPT-3 have been utilized to decode complex medical jargon and abbreviations in electronic health records, significantly improving the extraction of actionable medical information without extensive manual labeling \cite{agrawal2022large}. Similarly, in e-commerce, pre-trained models like GPT-4 and LLama2 have been employed to extract structured data, such as product attribute values, from unstructured text, enabling better product search and comparison features \cite{brinkmann2024product}. 

\subsection{Advancements in Structured Data Models}
Pre-trained language models have transformed structured data extraction and utilization in e-commerce. Traditional methods like BERT often require extensive task-specific training data and face limitations in generalizing to unseen attribute values \cite{brinkmann2024product}. In contrast, modern LLMs like GPT-4 and LLama2 excel in zero-shot and few-shot scenarios, offering robust solutions for attribute extraction with minimal training \cite{brinkmann2024product}. Additionally, synthetic data generation has been integrated into structured data models, addressing data sparsity and improving model performance by enhancing training datasets with diverse and realistic examples \cite{skondras2023generating}.

\subsection{Sequence-to-Sequence Architectures}
Research has shown that integrating pre-trained language model representations into sequence-to-sequence architectures can yield substantial gains in tasks like neural machine translation and abstractive summarization. For example, incorporating pre-trained embeddings into the encoder network of transformer models has significantly enhanced translation accuracy, particularly in low-resource settings, demonstrating improvements in BLEU scores and overall model performance \cite{edunov-etal-2019-pre}.

\subsection{E-commerce Systems and Personalized Solutions}
E-commerce systems increasingly leverage pre-trained models like E-BERT, which integrates domain-specific knowledge to improve recommendation accuracy, aspect extraction, and product classification \cite{zhang2021ebert}. Fine-tuned models like LLama2 have demonstrated effectiveness in generating enhanced product descriptions validated by metrics such as NDCG, click-through rates, and human assessments \cite{zhou2023leveraging}. Furthermore, combining collaborative filtering with LLMs has advanced recommendation systems, enabling personalized and accurate suggestions for users \cite{xu2024emerging}.

\section{Structured Datasets and Their Importance}

Structured datasets in formats like JSON, CSV, and TSV are essential for training LLMs to handle organized data effectively, with JSON being particularly popular for its clear structure and web compatibility \cite{singha2023tabularrepresentationnoisyoperators}. Key datasets include QTSUMM, which supports structured summarization \cite{zhao2023qtsummqueryfocusedsummarizationtabular}, and PROMAP, which standardizes product attributes for improved e-commerce interoperability \cite{macková2023promapdatasetsproductmapping}. WikiTableT focuses on table-based question answering, TabFact trains models for factual verification using paired tables and true/false statements \cite{2019TabFactA}, and datasets like ToTTo \cite{parikh2020tottocontrolledtabletotextgeneration} and LogicNLG \cite{chen2020logicalnaturallanguagegeneration} extend LLM capabilities by generating coherent, contextually relevant, and logically sound text from structured inputs.
The eC-Tab2Text dataset advances Query-Focused Table Summarization specifically for e-commerce data, addressing challenges like diverse product attributes and user-specific queries. These datasets collectively enhance structured data transformation into human-centric narratives, improving search accuracy and recommendation systems in query-specific applications. Additionally, synthetic data generation increases their utility by addressing data shortages and aiding model generalization \cite{suri2023largelanguagemodelsdecision}.

\subsection{Notable Structured Datasets}
\begin{itemize}
    \item \textbf{QTSUMM Dataset}: Supports structured summarization and information retrieval by providing JSON-formatted entries tailored for query-focused tasks \cite{zhao2023qtsummqueryfocusedsummarizationtabular}.
    \item \textbf{PROMAP Dataset}: Focuses on product attribute mapping, improving e-commerce interoperability by standardizing product attributes across descriptions \cite{macková2023promapdatasetsproductmapping}.
    \item \textbf{WikiTableT}: Designed for table-based question answering, this dataset contains structured tabular data from Wikipedia to enhance knowledge retrieval \cite{chen2021wikitabletlargescaledatatotextdataset}.
    \item \textbf{TabFact}: Pairs tables with true/false statements for fact verification tasks, helping reduce hallucinations in model outputs \cite{chen2020tabfactlargescaledatasettablebased}.
\end{itemize}

Table \ref{tab:datasets} shows a comparison between eC-Tab2Text and existing table-to-text generation datasets, highlighting the diversity and scope of structured data available for training and evaluation. This table is adapted from \cite{zhao2023qtsummqueryfocusedsummarizationtabular}
\begin{table*}[ht]
    \footnotesize
    \centering
    \caption{Comparison between eC-Tab2Text and existing table-to-text generation datasets. \small{Adapted from \cite{zhao2023qtsummqueryfocusedsummarizationtabular}}}
    \renewcommand{\arraystretch}{1.1} % Adjusts the row spacing
    \resizebox{\textwidth}{!} 
    { 
    \begin{tblr}{hline{1,2,Z} = 0.8pt, hline{3-Y} = 0.2pt,
                 colspec = {Q[l,m, 13em] Q[l,m, 6em] Q[c,m, 8em] Q[c,m, 5em] Q[l,m, 14em]},
                 colsep  = 4pt,
                 row{1}  = {0.4cm, font=\bfseries, bg=gray!30},
                 row{2-Z} = {0.2cm},
                 }
\textbf{Dataset}       & \textbf{Table Source} & \textbf{\# Tables / Statements} & \textbf{\# Words / Statement} & \textbf{Explicit Control}\\ 
\SetCell[c=5]{c} \textit{Single-sentence Table-to-Text}\\
ToTTo \cite{parikh2020tottocontrolledtabletotextgeneration}   & Wikipedia        & 83,141 / 83,141                  & 17.4                          & Table region      \\
LOGICNLG \cite{chen2020logicalnaturallanguagegeneration} & Wikipedia        & 7,392 / 36,960                  & 14.2                          & Table regions      \\ 
HiTab \cite{cheng-etal-2022-hitab}   & Statistics web   & 3,597 / 10,672                  & 16.4                          & Table regions \& reasoning operator \\ 
\SetCell[c=5]{c} \textit{Generic Table Summarization}\\
ROTOWIRE \cite{wiseman2017challengesdatatodocumentgeneration} & NBA games      & 4,953 / 4,953                   & 337.1                         & \textbf{\textit{X}}                   \\
SciGen \cite{moosavi2021scigen} & Sci-Paper      & 1,338 / 1,338                   & 116.0                         & \textbf{\textit{X}}                   \\
NumericNLG \cite{suadaa-etal-2021-towards} & Sci-Paper   & 1,355 / 1,355                   & 94.2                          & \textbf{\textit{X}}                    \\
\SetCell[c=5]{c} \textit{Table Question Answering}\\
FeTaQA \cite{nan2021fetaqafreeformtablequestion}     & Wikipedia      & 10,330 / 10,330                 & 18.9                          & Queries rewritten from ToTTo \\
\SetCell[c=5]{c} \textit{Query-Focused Table Summarization}\\
QTSumm \cite{zhao2023qtsummqueryfocusedsummarizationtabular}                        & Wikipedia      & 2,934 / 7,111                   & 68.0                          & Queries from real-world scenarios\\ 
\textbf{eC-Tab2Text} (\textit{ours})                           & e-Commerce products      & 1,452 / 3354                   & 56.61                          & Queries from e-commerce products\\
    \end{tblr}
    }
\label{tab:datasets}
\end{table*}

\subsection{Advancements Through Synthetic Data Generation}
Synthetic data generation techniques have enhanced the versatility of structured datasets, addressing data shortages and improving generalization capabilities. For example, synthetic data generated by LLMs like ChatGPT has been used in resume classification to augment real-world datasets, resulting in improved model accuracy and robustness across various applications \cite{skondras2023generating}.

\section{Evaluation Metrics for LLMs}

Evaluating the performance of large language models requires comprehensive metrics that reflect their capabilities across different dimensions. Traditional metrics like BLEU and ROUGE assess the quality of text generation by comparing outputs to reference texts \cite{zhang2022opt}. However, newer methods have introduced specialized metrics for diverse tasks.

\subsection{Faithfulness and Correctness}
Faithfulness measures the factual accuracy of generated content by ensuring that outputs are grounded in input data \cite{madsen-etal-2022-evaluating}. Correctness focuses on syntactic and grammatical quality, ensuring coherence and linguistic accuracy \cite{yao2023predictinggeneralizationperformancecorrectness}. Advanced evaluators like G-Eval and Prometheus provide automated scoring for these metrics, enhancing large-scale evaluation processes \cite{kim2024prometheus2opensource}.
