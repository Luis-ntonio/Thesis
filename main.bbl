\begin{thebibliography}{88}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal and Lavie(2008)]{Agarwal2008Meteor}
Abhaya Agarwal and Alon Lavie.
\newblock Meteor, m-bleu and m-ter: evaluation metrics for high-correlation with human rankings of machine translation output.
\newblock In \emph{Proceedings of the Third Workshop on Statistical Machine Translation}, StatMT '08, page 115–118, USA, 2008. Association for Computational Linguistics.
\newblock ISBN 9781932432091.

\bibitem[Agrawal et~al.(2022)Agrawal, Hegselmann, Lang, Kim, and Sontag]{agrawal2022large}
Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim, and David Sontag.
\newblock Large language models are few-shot clinical information extractors.
\newblock In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, \emph{Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing}, pages 1998--2022, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.emnlp-main.130}.
\newblock URL \url{https://aclanthology.org/2022.emnlp-main.130}.

\bibitem[Barratt and Sharma(2018)]{Barratt2018OptimizingFG}
Shane~T. Barratt and Rishi Sharma.
\newblock Optimizing for generalization in machine learning with cross-validation gradients.
\newblock \emph{ArXiv}, abs/1805.07072, 2018.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:29160606}.

\bibitem[Bergmeir and Benítez(2012)]{Bergmeir2012On}
C.~Bergmeir and J.~M. Benítez.
\newblock On the use of cross-validation for time series predictor evaluation.
\newblock \emph{Inf. Sci.}, 191:\penalty0 192--213, 2012.
\newblock \doi{10.1016/j.ins.2011.12.028}.

\bibitem[Brinkmann et~al.(2024)Brinkmann, Shraga, and Bizer]{brinkmann2024product}
Alexander Brinkmann, Roee Shraga, and Christian Bizer.
\newblock Product attribute value extraction using large language models, 2024.

\bibitem[Carmack et~al.(2012)Carmack, Spence, and Schucany]{carmack2012generalised}
Patrick~S. Carmack, Jeffrey~S. Spence, and W.~R. Schucany.
\newblock Generalised correlated cross-validation.
\newblock \emph{Journal of Nonparametric Statistics}, 24:\penalty0 269 -- 282, 2012.
\newblock \doi{10.1080/10485252.2012.655733}.

\bibitem[Catani and Leifer(2020)]{Catani2020A}
L.~Catani and M.~Leifer.
\newblock A mathematical framework for operational fine tunings.
\newblock \emph{Quantum}, 7:\penalty0 948, 2020.
\newblock \doi{10.22331/q-2023-03-16-948}.

\bibitem[Chang et~al.(2024)Chang, Wang, Wang, Wu, Yang, Zhu, Chen, Yi, Wang, Wang, Ye, Zhang, Chang, Yu, Yang, and Xie]{Chang2023ASO}
Yupeng Chang, Xu~Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi~Chang, Philip~S. Yu, Qiang Yang, and Xing Xie.
\newblock A survey on evaluation of large language models.
\newblock \emph{ACM Trans. Intell. Syst. Technol.}, 15\penalty0 (3), March 2024.
\newblock ISSN 2157-6904.
\newblock \doi{10.1145/3641289}.
\newblock URL \url{https://doi.org/10.1145/3641289}.

\bibitem[Chen et~al.(2022)Chen, Yin, Shang, Jiang, Qin, Wang, Wang, Chen, Liu, and Liu]{chen-etal-2022-bert2bert}
Cheng Chen, Yichun Yin, Lifeng Shang, Xin Jiang, Yujia Qin, Fengyu Wang, Zhi Wang, Xiao Chen, Zhiyuan Liu, and Qun Liu.
\newblock bert2{BERT}: Towards reusable pretrained language models.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 2134--2148, Dublin, Ireland, May 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.acl-long.151}.
\newblock URL \url{https://aclanthology.org/2022.acl-long.151}.

\bibitem[Chen et~al.(2021)Chen, Wiseman, and Gimpel]{chen2021wikitabletlargescaledatatotextdataset}
Mingda Chen, Sam Wiseman, and Kevin Gimpel.
\newblock {W}iki{T}able{T}: A large-scale data-to-text dataset for generating {W}ikipedia article sections.
\newblock In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, \emph{Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021}, pages 193--209, Online, August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.findings-acl.17}.
\newblock URL \url{https://aclanthology.org/2021.findings-acl.17}.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Chen, Su, Chen, and Wang]{chen2020logicalnaturallanguagegeneration}
Wenhu Chen, Jianshu Chen, Yu~Su, Zhiyu Chen, and William~Yang Wang.
\newblock Logical natural language generation from open-domain tables.
\newblock In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, editors, \emph{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, pages 7929--7942, Online, July 2020{\natexlab{a}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.708}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.708}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Wang, Chen, Zhang, Wang, Li, Zhou, and Wang]{2019TabFactA}
Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, and William~Yang Wang.
\newblock Tabfact: A large-scale dataset for table-based fact verification.
\newblock In \emph{International Conference on Learning Representations}, 2020{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=rkeJRhNYDH}.

\bibitem[Cheng et~al.(2022)Cheng, Dong, Wang, Jia, Guo, Gao, Han, Lou, and Zhang]{cheng-etal-2022-hitab}
Zhoujun Cheng, Haoyu Dong, Zhiruo Wang, Ran Jia, Jiaqi Guo, Yan Gao, Shi Han, Jian-Guang Lou, and Dongmei Zhang.
\newblock {H}i{T}ab: A hierarchical table dataset for question answering and natural language generation.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 1094--1110, Dublin, Ireland, May 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.acl-long.78}.
\newblock URL \url{https://aclanthology.org/2022.acl-long.78}.

\bibitem[Dang(2006)]{dang-2006-duc}
Hoa~Trang Dang.
\newblock {DUC} 2005: Evaluation of question-focused summarization systems.
\newblock In Tat-Seng Chua, Jade Goldstein, Simone Teufel, and Lucy Vanderwende, editors, \emph{Proceedings of the Workshop on Task-Focused Summarization and Question Answering}, pages 48--55, Sydney, Australia, July 2006. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/W06-0707}.

\bibitem[Debbah(2023)]{10305960}
Mérouane Debbah.
\newblock Large language models for telecom.
\newblock In \emph{2023 Eighth International Conference on Fog and Mobile Edge Computing (FMEC)}, pages 3--4, 2023.
\newblock \doi{10.1109/FMEC59375.2023.10305960}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bertpretrainingdeepbidirectional}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding, 2019.
\newblock URL \url{https://arxiv.org/abs/1810.04805}.

\bibitem[Dobre(2015)]{Dobre2015ACB}
Iuliana Dobre.
\newblock A comparison between bleu and meteor metrics used for assessing students within an informatics discipline course.
\newblock \emph{Procedia - Social and Behavioral Sciences}, 180:\penalty0 305--312, 2015.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:60373804}.

\bibitem[Edunov et~al.(2019)Edunov, Baevski, and Auli]{edunov-etal-2019-pre}
Sergey Edunov, Alexei Baevski, and Michael Auli.
\newblock Pre-trained language model representations for language generation.
\newblock In Jill Burstein, Christy Doran, and Thamar Solorio, editors, \emph{Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)}, pages 4052--4059, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1409}.
\newblock URL \url{https://aclanthology.org/N19-1409}.

\bibitem[Fan et~al.(2023)Fan, Kang, Ma, Chen, Wei, Fan, and Yang]{fan2023fatellm}
Tao Fan, Yan Kang, Guoqiang Ma, Weijing Chen, Wenbin Wei, Lixin Fan, and Qiang Yang.
\newblock Fate-llm: A industrial grade federated learning framework for large language models.
\newblock \emph{Symposium on Advances and Open Problems in Large Language Models (LLM@IJCAI'23)}, 2023.

\bibitem[Ganesan(2018)]{Ganesan2015ROUGE}
Kavita Ganesan.
\newblock Rouge 2.0: Updated and improved measures for evaluation of summarization tasks, 2018.
\newblock URL \url{https://arxiv.org/abs/1803.01937}.

\bibitem[Gao et~al.(2024)Gao, Zhang, Chen, and Lam]{gao2024jsontuning}
Chang Gao, Wenxuan Zhang, Guizhen Chen, and Wai Lam.
\newblock Jsontuning: Towards generalizable, robust, and controllable instruction tuning, 2024.

\bibitem[Gat et~al.(2024)Gat, Calderon, Feder, Chapanin, Sharma, and Reichart]{gat2023faithfulexplanationsblackboxnlp}
Yair~Ori Gat, Nitay Calderon, Amir Feder, Alexander Chapanin, Amit Sharma, and Roi Reichart.
\newblock Faithful explanations of black-box {NLP} models using {LLM}-generated counterfactuals.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=UMfcdRIotC}.

\bibitem[Giorgi et~al.(2023)Giorgi, Soldaini, Wang, Bader, Lo, Wang, and Cohan]{giorgi-etal-2023-open}
John Giorgi, Luca Soldaini, Bo~Wang, Gary Bader, Kyle Lo, Lucy Wang, and Arman Cohan.
\newblock Open domain multi-document summarization: A comprehensive study of model brittleness under retrieval.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Findings of the Association for Computational Linguistics: EMNLP 2023}, pages 8177--8199, Singapore, December 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.findings-emnlp.549}.
\newblock URL \url{https://aclanthology.org/2023.findings-emnlp.549}.

\bibitem[He and Abisado(2023)]{He2023ReviewOS}
Aixiang He and Mideth~B. Abisado.
\newblock Review on sentiment analysis of e-commerce product comments.
\newblock \emph{2023 IEEE 15th International Conference on Advanced Infocomm Technology (ICAIT)}, pages 398--406, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:266601440}.

\bibitem[He et~al.(2023)He, Mao, Lin, Ruan, Lan, Feng, and Cambria]{he2023survey}
Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, and Erik Cambria.
\newblock A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics, 2023.

\bibitem[Jacovi and Goldberg(2020)]{jacovi-goldberg-2020-towards}
Alon Jacovi and Yoav Goldberg.
\newblock Towards faithfully interpretable {NLP} systems: How should we define and evaluate faithfulness?
\newblock In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, editors, \emph{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, pages 4198--4205, Online, July 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.386}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.386}.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, de~las Casas, Bressand, Lengyel, Lample, Saulnier, Lavaud, Lachaux, Stock, Scao, Lavril, Wang, Lacroix, and Sayed]{jiang2023mistral}
Albert~Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio~Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven~Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William~El Sayed.
\newblock Mistral 7b, 2023.

\bibitem[Jiang and Wang(2017)]{jiang2017markov}
Gaoxia Jiang and Wenjian Wang.
\newblock Markov cross-validation for time series model evaluations.
\newblock \emph{Inf. Sci.}, 375:\penalty0 219--233, 2017.
\newblock \doi{10.1016/j.ins.2016.09.061}.

\bibitem[Kim et~al.(2024{\natexlab{a}})Kim, Shin, Cho, Jang, Longpre, Lee, Yun, Shin, Kim, Thorne, and Seo]{kim2024prometheusinducingfinegrainedevaluation}
Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, and Minjoon Seo.
\newblock Prometheus: Inducing fine-grained evaluation capability in language models.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=8euJaTveKw}.

\bibitem[Kim et~al.(2024{\natexlab{b}})Kim, Suk, Cho, Longpre, Kim, Yoon, Son, Cho, Shafayat, Baek, Park, Hwang, Jo, Cho, Shin, Lee, Oh, Lee, Ho, Joo, Ko, Lee, Chae, Shin, Jang, Ye, Lin, Welleck, Neubig, Lee, Lee, and Seo]{kim2024biggenbenchprincipledbenchmark}
Seungone Kim, Juyoung Suk, Ji~Yong Cho, Shayne Longpre, Chaeeun Kim, Dongkeun Yoon, Guijin Son, Yejin Cho, Sheikh Shafayat, Jinheon Baek, Sue~Hyun Park, Hyeonbin Hwang, Jinkyung Jo, Hyowon Cho, Haebin Shin, Seongyun Lee, Hanseok Oh, Noah Lee, Namgyu Ho, Se~June Joo, Miyoung Ko, Yoonjoo Lee, Hyungjoo Chae, Jamin Shin, Joel Jang, Seonghyeon Ye, Bill~Yuchen Lin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, and Minjoon Seo.
\newblock The biggen bench: A principled benchmark for fine-grained evaluation of language models with language models, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2406.05761}.

\bibitem[Kim et~al.(2024{\natexlab{c}})Kim, Suk, Longpre, Lin, Shin, Welleck, Neubig, Lee, Lee, and Seo]{kim2024prometheus2opensource}
Seungone Kim, Juyoung Suk, Shayne Longpre, Bill~Yuchen Lin, Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, and Minjoon Seo.
\newblock Prometheus 2: An open source language model specialized in evaluating other language models.
\newblock In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, \emph{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}, pages 4334--4353, Miami, Florida, USA, November 2024{\natexlab{c}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.emnlp-main.248}.
\newblock URL \url{https://aclanthology.org/2024.emnlp-main.248}.

\bibitem[Lalor et~al.(2017)Lalor, Wu, and Yu]{Lalor2017Improving}
John~P. Lalor, Hao Wu, and Hong Yu.
\newblock Improving machine learning ability with fine-tuning.
\newblock \emph{ArXiv}, abs/1702.08563, 2017.

\bibitem[Lavie and Agarwal(2007)]{10.5555/1626355.1626389}
Alon Lavie and Abhaya Agarwal.
\newblock Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments.
\newblock In \emph{Proceedings of the Second Workshop on Statistical Machine Translation}, StatMT '07, pages 228--231, USA, 2007. Association for Computational Linguistics.

\bibitem[Lavie et~al.(2004)Lavie, Sagae, and Jayaraman]{lavie-etal-2004-significance}
Alon Lavie, Kenji Sagae, and Shyamsundar Jayaraman.
\newblock The significance of recall in automatic metrics for {MT} evaluation.
\newblock In Robert~E. Frederking and Kathryn~B. Taylor, editors, \emph{Proceedings of the 6th Conference of the Association for Machine Translation in the Americas: Technical Papers}, pages 134--143, Washington, USA, September 28 - October 2 2004. Springer.
\newblock URL \url{https://link.springer.com/chapter/10.1007/978-3-540-30194-3_16}.

\bibitem[Lee et~al.(2023)Lee, Lee, Moon, Park, Seo, Eo, Koo, and Lim]{Lee2023ASO}
Seungjun Lee, Jungseob Lee, Hyeonseok Moon, Chanjun Park, Jaehyung Seo, Sugyeong Eo, Seonmin Koo, and Heuiseok Lim.
\newblock A survey on evaluation metrics for machine translation.
\newblock \emph{Mathematics}, 11\penalty0 (4), 2023.
\newblock ISSN 2227-7390.
\newblock \doi{10.3390/math11041006}.
\newblock URL \url{https://www.mdpi.com/2227-7390/11/4/1006}.

\bibitem[Liang(2020)]{Liang_2020}
Jia-Hui Liang.
\newblock Application of big data technology in product selection on cross-border e-commerce platforms.
\newblock \emph{Journal of Physics: Conference Series}, 1601\penalty0 (3):\penalty0 032012, jul 2020.
\newblock \doi{10.1088/1742-6596/1601/3/032012}.
\newblock URL \url{https://dx.doi.org/10.1088/1742-6596/1601/3/032012}.

\bibitem[Lin(2004)]{lin-2004-rouge}
Chin-Yew Lin.
\newblock {ROUGE}: A package for automatic evaluation of summaries.
\newblock In \emph{Text Summarization Branches Out}, pages 74--81, Barcelona, Spain, July 2004. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/W04-1013}.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Sha, and Peng]{Liu2023Improving}
Jiaxing Liu, Chaofeng Sha, and Xin Peng.
\newblock Improving fine-tuning pre-trained models on small source code datasets via variational information bottleneck.
\newblock \emph{2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, pages 331--342, 2023{\natexlab{a}}.
\newblock \doi{10.1109/SANER56733.2023.00039}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Iter, Xu, Wang, Xu, and Zhu]{liu2023gevalnlgevaluationusing}
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu.
\newblock {G}-eval: {NLG} evaluation using gpt-4 with better human alignment.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 2511--2522, Singapore, December 2023{\natexlab{b}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.emnlp-main.153}.
\newblock URL \url{https://aclanthology.org/2023.emnlp-main.153}.

\bibitem[Liu et~al.(2024)Liu, Cao, Liu, Ding, and Jin]{liu2024datasetslargelanguagemodels}
Yang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, and Lianwen Jin.
\newblock Datasets for large language models: A comprehensive survey, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.18041}.

\bibitem[Loshchilov and Hutter(2019{\natexlab{a}})]{loshchilov2018decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In \emph{International Conference on Learning Representations}, 2019{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=Bkg6RiCqY7}.

\bibitem[Loshchilov and Hutter(2019{\natexlab{b}})]{loshchilov2019decoupledweightdecayregularization}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization, 2019{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/1711.05101}.

\bibitem[Lyu et~al.(2024)Lyu, Apidianaki, and Callison-Burch]{lyu2024faithfulmodelexplanationnlp}
Qing Lyu, Marianna Apidianaki, and Chris Callison-Burch.
\newblock Towards faithful model explanation in {NLP}: A survey.
\newblock \emph{Computational Linguistics}, 50\penalty0 (2):\penalty0 657--723, June 2024.
\newblock \doi{10.1162/coli_a_00511}.
\newblock URL \url{https://aclanthology.org/2024.cl-2.6}.

\bibitem[Mackov\'{a} and Pil\'{a}t(2024{\natexlab{a}})]{macková2023promap}
Kate\v{r}ina Mackov\'{a} and Martin Pil\'{a}t.
\newblock Promap: Product mapping datasets.
\newblock In \emph{Advances in Information Retrieval: 46th European Conference on Information Retrieval, ECIR 2024, Glasgow, UK, March 24–28, 2024, Proceedings, Part II}, page 159–172, Berlin, Heidelberg, 2024{\natexlab{a}}. Springer-Verlag.
\newblock ISBN 978-3-031-56059-0.
\newblock \doi{10.1007/978-3-031-56060-6_11}.
\newblock URL \url{https://doi.org/10.1007/978-3-031-56060-6_11}.

\bibitem[Mackov\'{a} and Pil\'{a}t(2024{\natexlab{b}})]{macková2023promapdatasetsproductmapping}
Kate\v{r}ina Mackov\'{a} and Martin Pil\'{a}t.
\newblock Promap: Product mapping datasets.
\newblock In \emph{Advances in Information Retrieval: 46th European Conference on Information Retrieval, ECIR 2024, Glasgow, UK, March 24–28, 2024, Proceedings, Part II}, page 159–172, Berlin, Heidelberg, 2024{\natexlab{b}}. Springer-Verlag.
\newblock ISBN 978-3-031-56059-0.
\newblock \doi{10.1007/978-3-031-56060-6_11}.
\newblock URL \url{https://doi.org/10.1007/978-3-031-56060-6_11}.

\bibitem[Madsen et~al.(2022)Madsen, Meade, Adlakha, and Reddy]{madsen-etal-2022-evaluating}
Andreas Madsen, Nicholas Meade, Vaibhav Adlakha, and Siva Reddy.
\newblock Evaluating the faithfulness of importance measures in {NLP} by recursively masking allegedly important tokens and retraining.
\newblock In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, \emph{Findings of the Association for Computational Linguistics: EMNLP 2022}, pages 1731--1751, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.findings-emnlp.125}.
\newblock URL \url{https://aclanthology.org/2022.findings-emnlp.125}.

\bibitem[Maples(2017)]{Maples2017TheR}
Sydney Maples.
\newblock The rouge-ar : A proposed extension to the rouge evaluation metric for abstractive text summarization.
\newblock 2017.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:34483154}.

\bibitem[Moosavi et~al.(2021)Moosavi, R{\"u}ckl{\'e}, Roth, and Gurevych]{moosavi2021scigen}
Nafise~Sadat Moosavi, Andreas R{\"u}ckl{\'e}, Dan Roth, and Iryna Gurevych.
\newblock Scigen: a dataset for reasoning-aware text generation from scientific tables.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)}, 2021.
\newblock URL \url{https://openreview.net/forum?id=Jul-uX7EV_I}.

\bibitem[Muntjir and Siddiqui(2016)]{Muntjir2016}
Mohd Muntjir and Ahmad~Tasnim Siddiqui.
\newblock An enhanced framework with advanced study to incorporate the searching of e-commerce products using modernization of database queries.
\newblock \emph{International Journal of Advanced Computer Science and Applications}, 7\penalty0 (5), 2016.
\newblock \doi{10.14569/IJACSA.2016.070514}.
\newblock URL \url{http://dx.doi.org/10.14569/IJACSA.2016.070514}.

\bibitem[Nan et~al.(2022)Nan, Hsieh, Mao, Lin, Verma, Zhang, Kry{\'s}ci{\'n}ski, Schoelkopf, Kong, Tang, Mutuma, Rosand, Trindade, Bandaru, Cunningham, Xiong, Radev, and Radev]{nan2021fetaqafreeformtablequestion}
Linyong Nan, Chiachun Hsieh, Ziming Mao, Xi~Victoria Lin, Neha Verma, Rui Zhang, Wojciech Kry{\'s}ci{\'n}ski, Hailey Schoelkopf, Riley Kong, Xiangru Tang, Mutethia Mutuma, Ben Rosand, Isabel Trindade, Renusree Bandaru, Jacob Cunningham, Caiming Xiong, Dragomir Radev, and Dragomir Radev.
\newblock {F}e{T}a{QA}: Free-form table question answering.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 10:\penalty0 35--49, 2022.
\newblock \doi{10.1162/tacl_a_00446}.
\newblock URL \url{https://aclanthology.org/2022.tacl-1.3}.

\bibitem[Naveed et~al.(2024)Naveed, Khan, Qiu, Saqib, Anwar, Usman, Akhtar, Barnes, and Mian]{naveed2024comprehensive}
Humza Naveed, Asad~Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Naveed Akhtar, Nick Barnes, and Ajmal Mian.
\newblock A comprehensive overview of large language models, 2024.

\bibitem[Ng and Abrecht(2015)]{Ng2015Better}
Jun-Ping Ng and Viktoria Abrecht.
\newblock Better summarization evaluation with word embeddings for {ROUGE}.
\newblock In Llu{\'\i}s M{\`a}rquez, Chris Callison-Burch, and Jian Su, editors, \emph{Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}, pages 1925--1930, Lisbon, Portugal, September 2015. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D15-1222}.
\newblock URL \url{https://aclanthology.org/D15-1222}.

\bibitem[OpenAI et~al.(2024)OpenAI, Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, Avila, Babuschkin, Balaji, Balcom, Baltescu, Bao, Bavarian, Belgum, Bello, Berdine, Bernadett-Shapiro, Berner, Bogdonoff, Boiko, Boyd, Brakman, Brockman, Brooks, Brundage, Button, Cai, Campbell, Cann, Carey, Carlson, Carmichael, Chan, Chang, Chantzis, Chen, Chen, Chen, Chen, Chen, Chess, Cho, Chu, Chung, Cummings, Currier, Dai, Decareaux, Degry, Deutsch, Deville, Dhar, Dohan, Dowling, Dunning, Ecoffet, Eleti, Eloundou, Farhi, Fedus, Felix, Fishman, Forte, Fulford, Gao, Georges, Gibson, Goel, Gogineni, Goh, Gontijo-Lopes, Gordon, Grafstein, Gray, Greene, Gross, Gu, Guo, Hallacy, Han, Harris, He, Heaton, Heidecke, Hesse, Hickey, Hickey, Hoeschele, Houghton, Hsu, Hu, Hu, Huizinga, Jain, Jain, Jang, Jiang, Jiang, Jin, Jin, Jomoto, Jonn, Jun, Kaftan, Łukasz Kaiser, Kamali, Kanitscheider, Keskar, Khan, Kilpatrick, Kim, Kim, Kim, Kirchner, Kiros, Knight, Kokotajlo, Łukasz Kondraciuk, Kondrich, Konstantinidis, Kosic, Krueger, Kuo, Lampe, Lan, Lee, Leike, Leung, Levy, Li, Lim, Lin, Lin, Litwin, Lopez, Lowe, Lue, Makanju, Malfacini, Manning, Markov, Markovski, Martin, Mayer, Mayne, McGrew, McKinney, McLeavey, McMillan, McNeil, Medina, Mehta, Menick, Metz, Mishchenko, Mishkin, Monaco, Morikawa, Mossing, Mu, Murati, Murk, Mély, Nair, Nakano, Nayak, Neelakantan, Ngo, Noh, Ouyang, O'Keefe, Pachocki, Paino, Palermo, Pantuliano, Parascandolo, Parish, Parparita, Passos, Pavlov, Peng, Perelman, de~Avila Belbute~Peres, Petrov, de~Oliveira~Pinto, Michael, Pokorny, Pokrass, Pong, Powell, Power, Power, Proehl, Puri, Radford, Rae, Ramesh, Raymond, Real, Rimbach, Ross, Rotsted, Roussez, Ryder, Saltarelli, Sanders, Santurkar, Sastry, Schmidt, Schnurr, Schulman, Selsam, Sheppard, Sherbakov, Shieh, Shoker, Shyam, Sidor, Sigler, Simens, Sitkin, Slama, Sohl, Sokolowsky, Song, Staudacher, Such, Summers, Sutskever, Tang, Tezak, Thompson, Tillet, Tootoonchian, Tseng, Tuggle, Turley, Tworek, Uribe, Vallone, Vijayvergiya, Voss, Wainwright, Wang, Wang, Wang, Ward, Wei, Weinmann, Welihinda, Welinder, Weng, Weng, Wiethoff, Willner, Winter, Wolrich, Wong, Workman, Wu, Wu, Wu, Xiao, Xu, Yoo, Yu, Yuan, Zaremba, Zellers, Zhang, Zhang, Zhao, Zheng, Zhuang, Zhuk, and Zoph]{openai2024gpt4technicalreport}
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung~Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón~Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang~Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish~Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong~Wook Kim, Christina Kim, Yongjik Kim, Jan~Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak~Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott~Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O'Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de~Avila Belbute~Peres, Michael Petrov, Henrique~Ponde de~Oliveira~Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr~H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe~Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine~B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe~Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin~Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ~Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph.
\newblock Gpt-4 technical report, 2024.
\newblock URL \url{https://arxiv.org/abs/2303.08774}.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and jing Zhu]{Papineni02bleu:a}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock pages 311--318, 2002.

\bibitem[Parcalabescu and Frank(2024)]{parcalabescu2024measuringfaithfulnessselfconsistencynatural}
Letitia Parcalabescu and Anette Frank.
\newblock On measuring faithfulness or self-consistency of natural language explanations.
\newblock In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 6048--6089, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.acl-long.329}.
\newblock URL \url{https://aclanthology.org/2024.acl-long.329}.

\bibitem[Parikh et~al.(2020)Parikh, Wang, Gehrmann, Faruqui, Dhingra, Yang, and Das]{parikh2020tottocontrolledtabletotextgeneration}
Ankur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das.
\newblock {ToTTo}: A controlled table-to-text generation dataset.
\newblock In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pages 1173--1186, Online, November 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.89}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.89}.

\bibitem[Peng et~al.(2024)Peng, Ling, Chen, Sun, and Ning]{peng2024ecellmgeneralizinglargelanguage}
Bo~Peng, Xinyi Ling, Ziru Chen, Huan Sun, and Xia Ning.
\newblock ecellm: Generalizing large language models for e-commerce from large-scale, high-quality instruction data, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.08831}.

\bibitem[Pricebaba.com(2023)]{OnePlusNord35G2023}
Pricebaba.com.
\newblock Oneplus nord 3 5g - specifications and reviews, 2023.
\newblock URL \url{https://pricebaba.com/mobile/oneplus-nord-3-5g}.
\newblock Accessed: 2023-07-13.

\bibitem[Reiter(2018)]{Reiter2018A}
Ehud Reiter.
\newblock A structured review of the validity of {BLEU}.
\newblock \emph{Computational Linguistics}, 44\penalty0 (3):\penalty0 393--401, September 2018.
\newblock \doi{10.1162/coli_a_00322}.
\newblock URL \url{https://aclanthology.org/J18-3002}.

\bibitem[Ryali et~al.(2023)Ryali, S, Kaveri, and Comar]{10.1145/3583780.3615503}
Gayatri Ryali, Shreyas S, Sivaramakrishnan Kaveri, and Prakash~Mandayam Comar.
\newblock Trendspotter: Forecasting e-commerce product trends.
\newblock In \emph{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management}, CIKM '23, page 4808–4814, New York, NY, USA, 2023. Association for Computing Machinery.
\newblock ISBN 9798400701245.
\newblock \doi{10.1145/3583780.3615503}.
\newblock URL \url{https://doi.org/10.1145/3583780.3615503}.

\bibitem[Shachaf et~al.(2021)Shachaf, Brutzkus, and Globerson]{Shachaf2021A}
Gal Shachaf, Alon Brutzkus, and Amir Globerson.
\newblock A theoretical analysis of fine-tuning with linear teachers, 2021.
\newblock URL \url{https://arxiv.org/abs/2107.01641}.

\bibitem[Shi et~al.(2023)Shi, Wang, Zhang, Du, Han, Zhang, and Sun]{Shi2023Towards}
Ensheng Shi, Yanlin Wang, Hongyu Zhang, Lun Du, Shi Han, Dongmei Zhang, and Hongbin Sun.
\newblock Towards efficient fine-tuning of pre-trained code models: An experimental study and beyond.
\newblock \emph{Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis}, 2023.
\newblock \doi{10.1145/3597926.3598036}.

\bibitem[Shvachko et~al.(2010)Shvachko, Kuang, Radia, and Chansler]{5496972}
Konstantin Shvachko, Hairong Kuang, Sanjay Radia, and Robert Chansler.
\newblock The hadoop distributed file system.
\newblock In \emph{2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)}, pages 1--10, 2010.
\newblock \doi{10.1109/MSST.2010.5496972}.

\bibitem[Skondras et~al.(2023)Skondras, Zervas, and Tzimas]{skondras2023generating}
Panagiotis Skondras, Panagiotis Zervas, and Giannis Tzimas.
\newblock Generating synthetic resume data with large language models for enhanced job description classification.
\newblock \emph{Future Internet}, 15\penalty0 (11):\penalty0 363, 2023.

\bibitem[Steen et~al.(2023)Steen, Opitz, Frank, and Markert]{steen2023littlepushnlimodels}
Julius Steen, Juri Opitz, Anette Frank, and Katja Markert.
\newblock With a little push, {NLI} models can robustly and efficiently predict faithfulness.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}, pages 914--924, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-short.79}.
\newblock URL \url{https://aclanthology.org/2023.acl-short.79}.

\bibitem[Suadaa et~al.(2021)Suadaa, Kamigaito, Funakoshi, Okumura, and Takamura]{suadaa-etal-2021-towards}
Lya~Hulliyyatus Suadaa, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura, and Hiroya Takamura.
\newblock Towards table-to-text generation with numerical reasoning.
\newblock In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages 1451--1465, Online, August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.acl-long.115}.
\newblock URL \url{https://aclanthology.org/2021.acl-long.115}.

\bibitem[Tan and Teo(2015)]{10.1007/978-3-319-20895-4_34}
Wee-Kek Tan and Hock-Hai Teo.
\newblock Productpedia -- a collaborative electronic product catalog for ecommerce 3.0.
\newblock In Fiona Fui-Hoon~Nah and Chuan-Hoo Tan, editors, \emph{HCI in Business}, pages 370--381, Cham, 2015. Springer International Publishing.
\newblock ISBN 978-3-319-20895-4.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, Bikel, Blecher, Ferrer, Chen, Cucurull, Esiobu, Fernandes, Fu, Fu, Fuller, Gao, Goswami, Goyal, Hartshorn, Hosseini, Hou, Inan, Kardas, Kerkez, Khabsa, Kloumann, Korenev, Koura, Lachaux, Lavril, Lee, Liskovich, Lu, Mao, Martinet, Mihaylov, Mishra, Molybog, Nie, Poulton, Reizenstein, Rungta, Saladi, Schelten, Silva, Smith, Subramanian, Tan, Tang, Taylor, Williams, Kuan, Xu, Yan, Zarov, Zhang, Fan, Kambadur, Narang, Rodriguez, Stojnic, Edunov, and Scialom]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian~Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit~Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric~Michael Smith, Ranjan Subramanian, Xiaoqing~Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian~Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom.
\newblock Llama 2: Open foundation and fine-tuned chat models, 2023.

\bibitem[Varshney et~al.(2022)Varshney, Mishra, and Baral]{varshney-etal-2022-towards}
Neeraj Varshney, Swaroop Mishra, and Chitta Baral.
\newblock Towards improving selective prediction ability of {NLP} systems.
\newblock In Spandana Gella, He~He, Bodhisattwa~Prasad Majumder, Burcu Can, Eleonora Giunchiglia, Samuel Cahyawijaya, Sewon Min, Maximilian Mozes, Xiang~Lorraine Li, Isabelle Augenstein, Anna Rogers, Kyunghyun Cho, Edward Grefenstette, Laura Rimell, and Chris Dyer, editors, \emph{Proceedings of the 7th Workshop on Representation Learning for NLP}, pages 221--226, Dublin, Ireland, May 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.repl4nlp-1.23}.
\newblock URL \url{https://aclanthology.org/2022.repl4nlp-1.23}.

\bibitem[Varshney(2024)]{Varshney_2024}
Tanay Varshney.
\newblock Build an llm-powered data agent for data analysis, Feb 2024.
\newblock URL \url{https://developer.nvidia.com/blog/build-an-llm-powered-data-agent-for-data-analysis/}.

\bibitem[Vrbancic and Podgorelec(2020)]{Vrbancic2020Transfer}
Grega Vrbancic and V.~Podgorelec.
\newblock Transfer learning with adaptive fine-tuning.
\newblock \emph{IEEE Access}, 8:\penalty0 196197--196211, 2020.
\newblock \doi{10.1109/ACCESS.2020.3034343}.

\bibitem[Wang et~al.(2023)Wang, Li, Yin, Wu, of~PsychologyTsinghua Laboratory~of Brain, Intelligence, University, Psychology, and University]{Wang2023Emotional}
Xuena Wang, Xueting Li, Zi~Yin, Yue Wu, Liu Jia~Department of~PsychologyTsinghua Laboratory~of Brain, Intelligence, Tsinghua University, Departmentof Psychology, and Renmin University.
\newblock Emotional intelligence of large language models.
\newblock \emph{ArXiv}, abs/2307.09042, 2023.
\newblock \doi{10.48550/arXiv.2307.09042}.

\bibitem[Wiseman et~al.(2017)Wiseman, Shieber, and Rush]{wiseman2017challengesdatatodocumentgeneration}
Sam Wiseman, Stuart Shieber, and Alexander Rush.
\newblock Challenges in data-to-document generation.
\newblock In Martha Palmer, Rebecca Hwa, and Sebastian Riedel, editors, \emph{Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing}, pages 2253--2263, Copenhagen, Denmark, September 2017. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D17-1239}.
\newblock URL \url{https://aclanthology.org/D17-1239}.

\bibitem[Xiao et~al.(2023)Xiao, Lin, and Han]{Xiao2023Offsite-Tuning:}
Guangxuan Xiao, Ji~Lin, and Song Han.
\newblock Offsite-tuning: Transfer learning without full model.
\newblock \emph{ArXiv}, abs/2302.04870, 2023.
\newblock \doi{10.48550/arXiv.2302.04870}.

\bibitem[Xie et~al.(2022)Xie, Wu, Shi, Zhong, Scholak, Yasunaga, Wu, Zhong, Yin, Wang, Zhong, Wang, Li, Boyle, Ni, Yao, Radev, Xiong, Kong, Zhang, Smith, Zettlemoyer, and Yu]{xie2022unifiedskgunifyingmultitaskingstructured}
Tianbao Xie, Chen~Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida~I. Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah~A. Smith, Luke Zettlemoyer, and Tao Yu.
\newblock Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models, 2022.
\newblock URL \url{https://arxiv.org/abs/2201.05966}.

\bibitem[Xu et~al.(2024)Xu, Wu, Liang, He, and Wang]{xu2024emerging}
Xiaonan Xu, Yichao Wu, Penghao Liang, Yuhang He, and Han Wang.
\newblock Emerging synergies between large language models and machine learning in ecommerce recommendations, 2024.

\bibitem[Yao and Koller(2024)]{yao2023predictinggeneralizationperformancecorrectness}
Yuekun Yao and Alexander Koller.
\newblock Predicting generalization performance with correctness discriminators.
\newblock In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, \emph{Findings of the Association for Computational Linguistics: EMNLP 2024}, pages 11725--11739, Miami, Florida, USA, November 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.findings-emnlp.686}.
\newblock URL \url{https://aclanthology.org/2024.findings-emnlp.686}.

\bibitem[Zhang et~al.(2021)Zhang, Yuan, Liu, Zhuang, Chen, and Xiong]{zhang2021ebert}
Denghui Zhang, Zixuan Yuan, Yanchi Liu, Fuzhen Zhuang, Haifeng Chen, and Hui Xiong.
\newblock E-bert: A phrase and product knowledge enhanced language model for e-commerce, 2021.

\bibitem[Zhang et~al.(2022{\natexlab{a}})Zhang, Li, Li, Zhang, Zhu, and Jin]{Zhang2022Fine-Tuning}
Haojie Zhang, Ge~Li, Jia Li, Zhongjin Zhang, Yuqi Zhu, and Zhi Jin.
\newblock Fine-tuning pre-trained language models effectively by optimizing subnetworks adaptively.
\newblock \emph{ArXiv}, abs/2211.01642, 2022{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2211.01642}.

\bibitem[Zhang et~al.(2023)Zhang, Dong, Li, Zhang, Sun, Wang, Li, Hu, Zhang, Wu, and Wang]{Zhang2023InstructionTF}
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, and Guoyin Wang.
\newblock Instruction tuning for large language models: A survey.
\newblock \emph{ArXiv}, abs/2308.10792, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:261049152}.

\bibitem[Zhang et~al.(2022{\natexlab{b}})Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan, Diab, Li, Lin, Mihaylov, Ott, Shleifer, Shuster, Simig, Koura, Sridhar, Wang, and Zettlemoyer]{zhang2022opt}
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi~Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit~Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer.
\newblock Opt: Open pre-trained transformer language models, 2022{\natexlab{b}}.

\bibitem[Zhang* et~al.(2020)Zhang*, Kishore*, Wu*, Weinberger, and Artzi]{zhang2020bertscoreevaluatingtextgeneration}
Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian~Q. Weinberger, and Yoav Artzi.
\newblock Bertscore: Evaluating text generation with bert.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SkeHuCVFDr}.

\bibitem[Zhao et~al.(2023{\natexlab{a}})Zhao, Zhou, Li, Tang, Wang, Hou, Min, Zhang, Zhang, Dong, Du, Yang, Chen, Chen, Jiang, Ren, Li, Tang, Liu, Liu, Nie, and Wen]{zhao2023survey}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.
\newblock A survey of large language models, 2023{\natexlab{a}}.

\bibitem[Zhao et~al.(2023{\natexlab{b}})Zhao, Qi, Nan, Mi, Liu, Zou, Han, Chen, Tang, Xu, Radev, and Cohan]{zhao2023qtsummqueryfocusedsummarizationtabular}
Yilun Zhao, Zhenting Qi, Linyong Nan, Boyu Mi, Yixin Liu, Weijin Zou, Simeng Han, Ruizhe Chen, Xiangru Tang, Yumo Xu, Dragomir Radev, and Arman Cohan.
\newblock {QTS}umm: Query-focused summarization over tabular data.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 1157--1172, Singapore, December 2023{\natexlab{b}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.emnlp-main.74}.
\newblock URL \url{https://aclanthology.org/2023.emnlp-main.74}.

\bibitem[Zheng et~al.(2024)Zheng, Zhang, Zhang, Ye, and Luo]{zheng2024llamafactory}
Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, and Zheyan Luo.
\newblock {L}lama{F}actory: Unified efficient fine-tuning of 100+ language models.
\newblock In Yixin Cao, Yang Feng, and Deyi Xiong, editors, \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)}, pages 400--410, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.acl-demos.38}.
\newblock URL \url{https://aclanthology.org/2024.acl-demos.38}.

\bibitem[Zhong et~al.(2021)Zhong, Yin, Yu, Zaidi, Mutuma, Jha, Awadallah, Celikyilmaz, Liu, Qiu, and Radev]{zhong-etal-2021-qmsum}
Ming Zhong, Da~Yin, Tao Yu, Ahmad Zaidi, Mutethia Mutuma, Rahul Jha, Ahmed~Hassan Awadallah, Asli Celikyilmaz, Yang Liu, Xipeng Qiu, and Dragomir Radev.
\newblock {QMS}um: A new benchmark for query-based multi-domain meeting summarization.
\newblock In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz~Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors, \emph{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 5905--5921, Online, June 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.naacl-main.472}.
\newblock URL \url{https://aclanthology.org/2021.naacl-main.472}.

\bibitem[Zhou et~al.(2023)Zhou, Liu, Acharya, Hong, Lee, and Wen]{zhou2023leveraging}
Jianghong Zhou, Bo~Liu, Jhalak Acharya, Yao Hong, Kuang-Chih Lee, and Musen Wen.
\newblock Leveraging large language models for enhanced product descriptions in e{C}ommerce.
\newblock In Sebastian Gehrmann, Alex Wang, Jo{\~a}o Sedoc, Elizabeth Clark, Kaustubh Dhole, Khyathi~Raghavi Chandu, Enrico Santus, and Hooman Sedghamiz, editors, \emph{Proceedings of the Third Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)}, pages 88--96, Singapore, December 2023. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2023.gem-1.8}.

\bibitem[Zhuang et~al.(2024)Zhuang, Zhang, Zheng, Du, Wang, Ren, Huang, Fu, Yue, and Chen]{zhuang2024structlm}
Alex Zhuang, Ge~Zhang, Tianyu Zheng, Xinrun Du, Junjie Wang, Weiming Ren, Wenhao Huang, Jie Fu, Xiang Yue, and Wenhu Chen.
\newblock Struct{LM}: Towards building generalist models for structured knowledge grounding.
\newblock In \emph{First Conference on Language Modeling}, 2024.
\newblock URL \url{https://openreview.net/forum?id=EKBPn7no4y}.

\end{thebibliography}
