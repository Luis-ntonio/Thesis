@misc{Bergmann_2024,
  title   = {Build an LLM-Powered Data Agent for Data Analysis},
  url     = {https://www.ibm.com/topics/fine-tuning},
  journal = {IBM},
  author  = {Bergmann, Dave},
  year    = {2024},
  month   = {March}
}

@misc{gao2024jsontuning,
  title         = {JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning},
  author        = {Chang Gao and Wenxuan Zhang and Guizhen Chen and Wai Lam},
  year          = {2024},
  eprint        = {2310.02953},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}


@misc{he2023survey,
  title         = {A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics},
  author        = {Kai He and Rui Mao and Qika Lin and Yucheng Ruan and Xiang Lan and Mengling Feng and Erik Cambria},
  year          = {2023},
  eprint        = {2310.05694},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
} 

@misc{jiang2023mistral,
  title         = {Mistral 7B},
  author        = {Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
  year          = {2023},
  eprint        = {2310.06825},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
} 

@misc{liu2023reviewergpt,
  title         = {ReviewerGPT? An Exploratory Study on Using Large Language Models for Paper Reviewing},
  author        = {Ryan Liu and Nihar B. Shah},
  year          = {2023},
  eprint        = {2306.00622},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{naveed2024comprehensive,
  title         = {A Comprehensive Overview of Large Language Models},
  author        = {Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
  year          = {2024},
  eprint        = {2307.06435},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{REDDY2023101304,
  title    = {Evaluating large language models for use in healthcare: A framework for translational value assessment},
  journal  = {Informatics in Medicine Unlocked},
  volume   = {41},
  pages    = {101304},
  year     = {2023},
  issn     = {2352-9148},
  doi      = {https://doi.org/10.1016/j.imu.2023.101304},
  url      = {https://www.sciencedirect.com/science/article/pii/S2352914823001508},
  author   = {Sandeep Reddy},
  abstract = {The recent focus on Large Language Models (LLMs) has yielded unprecedented discussion of their potential use in various domains, including healthcare. While showing considerable potential in performing human-capable tasks, LLMs have also demonstrated significant drawbacks, including generating misinformation, falsifying data, and contributing to plagiarism. These aspects are generally concerning but can be more severe in the context of healthcare. As LLMs are explored for utility in healthcare, including generating discharge summaries, interpreting medical records and providing medical advice, it is necessary to ensure safeguards around their use in healthcare. Notably, there must be an evaluation process that assesses LLMs for their natural language processing performance and their translational value. Complementing this assessment, a governance layer can ensure accountability and public confidence in such models. Such an evaluation framework is discussed and presented in this paper.}
}

@misc{singha2023tabular,
  title         = {Tabular Representation, Noisy Operators, and Impacts on Table Structure Understanding Tasks in LLMs},
  author        = {Ananya Singha and José Cambronero and Sumit Gulwani and Vu Le and Chris Parnin},
  year          = {2023},
  eprint        = {2310.10358},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{touvron2023llama,
  title         = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author        = {Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  year          = {2023},
  eprint        = {2307.09288},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{Varshney_2024,
  title   = {Build an LLM-Powered Data Agent for Data Analysis},
  url     = {https://developer.nvidia.com/blog/build-an-llm-powered-data-agent-for-data-analysis/},
  journal = {Nvidia Developer},
  author  = {Varshney, Tanay},
  year    = {2024},
  month   = {Feb}
}

@misc{wu2023survey,
  title         = {A Survey on Large Language Models for Recommendation},
  author        = {Likang Wu and Zhi Zheng and Zhaopeng Qiu and Hao Wang and Hongchao Gu and Tingjia Shen and Chuan Qin and Chen Zhu and Hengshu Zhu and Qi Liu and Hui Xiong and Enhong Chen},
  year          = {2023},
  eprint        = {2305.19860},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR}
}

@misc{zhao2023survey,
  title         = {A Survey of Large Language Models},
  author        = {Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  year          = {2023},
  eprint        = {2303.18223},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{zhuang2024structlm,
  title         = {StructLM: Towards Building Generalist Models for Structured Knowledge Grounding},
  author        = {Alex Zhuang and Ge Zhang and Tianyu Zheng and Xinrun Du and Junjie Wang and Weiming Ren and Stephen W. Huang and Jie Fu and Xiang Yue and Wenhu Chen},
  year          = {2024},
  eprint        = {2402.16671},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{fan2023fatellm,
      title={FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models}, 
      author={Tao Fan and Yan Kang and Guoqiang Ma and Weijing Chen and Wenbin Wei and Lixin Fan and Qiang Yang},
      year={2023},
      eprint={2310.10049},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{10305960,
  author={Debbah, Mérouane},
  booktitle={2023 Eighth International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={Large Language Models for Telecom}, 
  year={2023},
  volume={},
  number={},
  pages={3-4},
  keywords={Fault diagnosis;Sentiment analysis;Multi-access edge computing;Wireless networks;Computational modeling;Network security;Telecommunications},
  doi={10.1109/FMEC59375.2023.10305960}}

@inproceedings{xu-etal-2021-raise,
    title = "Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning",
    author = "Xu, Runxin  and
      Luo, Fuli  and
      Zhang, Zhiyuan  and
      Tan, Chuanqi  and
      Chang, Baobao  and
      Huang, Songfang  and
      Huang, Fei",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.749",
    doi = "10.18653/v1/2021.emnlp-main.749",
    pages = "9514--9528",
    abstract = "Recent pretrained language models extend from millions to billions of parameters. Thus the need to fine-tune an extremely large pretrained model with a limited training corpus arises in various downstream tasks. In this paper, we propose a straightforward yet effective fine-tuning technique, Child-Tuning, which updates a subset of parameters (called child network) of large pretrained models via strategically masking out the gradients of the non-child network during the backward process. Experiments on various downstream tasks in GLUE benchmark show that Child-Tuning consistently outperforms the vanilla fine-tuning by 1.5 8.6 average score among four different pretrained models, and surpasses the prior fine-tuning techniques by 0.6 1.3 points. Furthermore, empirical results on domain transfer and task transfer show that Child-Tuning can obtain better generalization performance by large margins.",
}

@misc{sun2023comparative,
      title={A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model}, 
      author={Xianghui Sun and Yunjie Ji and Baochang Ma and Xiangang Li},
      year={2023},
      eprint={2304.08109},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yu2022differentially,
      title={Differentially Private Fine-tuning of Language Models}, 
      author={Da Yu and Saurabh Naik and Arturs Backurs and Sivakanth Gopi and Huseyin A. Inan and Gautam Kamath and Janardhan Kulkarni and Yin Tat Lee and Andre Manoel and Lukas Wutschitz and Sergey Yekhanin and Huishuai Zhang},
      year={2022},
      eprint={2110.06500},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zheng2024llamafactory,
      title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models}, 
      author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Yongqiang Ma},
      year={2024},
      eprint={2403.13372},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhu2024lift,
title={{LIFT}: Efficient Layer-wise Fine-tuning for Large Model Models},
author={Ligeng Zhu and Lanxiang Hu and Ji Lin and Song Han},
year={2024},
url={https://openreview.net/forum?id=u0INlprg3U}
}

@misc{macková2023promap,
      title={ProMap: Datasets for Product Mapping in E-commerce}, 
      author={Kateřina Macková and Martin Pilát},
      year={2023},
      eprint={2309.06882},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{10.1007/978-3-319-20895-4_34,
author="Tan, Wee-Kek
and Teo, Hock-Hai",
editor="Fui-Hoon Nah, Fiona
and Tan, Chuan-Hoo",
title="Productpedia -- A Collaborative Electronic Product Catalog for Ecommerce 3.0",
booktitle="HCI in Business",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="370--381",
abstract="Despite the advancements made in ecommerce technologies over the past years, the inability to define and exchange semantically rich and accurate product information among ecommerce websites/applications has continued to intrigue researchers. This problem has taken on greater urgency because it impedes the realization of the full benefits of Ecommerce 3.0. The present research conceptualizes, designs and implements a cloud computing-based platform that enables global merchants to maintain a collaborative Electronic Product Catalog (EPC) known as Productpedia. This collaborative EPC platform addresses numerous shortcomings of prior researches by (1) maintaining a single centralized EPC database; (2) negating the need to synchronize and convert data; (3) creating an integrated meta-model ontology for merchants to define previously unclassified product information without the involvement of domain experts; and (4) enabling an Open Application Programming Interface based on RESTful web services to facilitate direct modification of the EPC database by even third-party applications.",
isbn="978-3-319-20895-4"
}

@inproceedings{10.1145/3583780.3615503,
author = {Ryali, Gayatri and S, Shreyas and Kaveri, Sivaramakrishnan and Comar, Prakash Mandayam},
title = {TrendSpotter: Forecasting E-commerce Product Trends},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615503},
doi = {10.1145/3583780.3615503},
abstract = {Internet users actively search for trending products on various social media services like Instagram and YouTube which serve as popular hubs for discovering and exploring fashionable and popular items. It is imperative for e-commerce giants to have the capability to accurately identify, predict and subsequently showcase these trending products to the customers. E-commerce stores can effectively cater to the evolving demands of the customer base and enhance the overall shopping experience by offering recent and most sought-after products in a timely manner. In this work we propose a framework for predicting and surfacing trending products in e-commerce stores, the first of its kind to the best of our knowledge. We begin by defining what constitutes a trending product using sound statistical tests. We then introduce a machine learning-based early trend prediction system called TrendSpotter to help users identify upcoming product trends. TrendSpotter is a unique adaptation of the state-of-the-art InceptionTime modelciteInceptionTime that predicts the future popularity of a product based on its current customer engagement, such as clicks, purchases, and other relevant product attributes. The effectiveness of our approach is demonstrated through A/B tests, where we first showcase the effectiveness of our statistical test based labeling strategy, resulting in an incremental sales lift of 59 bpsfootnotebps or basis points are a measure of percentages. 1 bps = 0.01\% across two experiments on home page and search page. Subsequently, we conduct a comparison between our machine learning model and the statistical labeling baseline and observe an additional sales gain of 14 bps, reflecting the importance of early identification of trending products.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {4808–4814},
numpages = {7},
keywords = {trends, time series, e-commerce, convolutional neural networks},
location = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
series = {CIKM '23}
}

@article{Liang_2020,
doi = {10.1088/1742-6596/1601/3/032012},
url = {https://dx.doi.org/10.1088/1742-6596/1601/3/032012},
year = {2020},
month = {jul},
publisher = {IOP Publishing},
volume = {1601},
number = {3},
pages = {032012},
author = {Jia-Hui Liang},
title = {Application of Big Data Technology in Product Selection on Cross-border E-commerce Platforms},
journal = {Journal of Physics: Conference Series},
abstract = {With Amazon as the study case, the application of big data in product selection on this e-commerce platform is studied. Two big data analysis tools commonly used in commerce, the MPP distributed database and the Hadoop distributed database, were analyzed. Based on big data technology, the search function of the platform, the analytical tools, and third-party data analytical tools, this study compared different levels of comments of customers for the same type of products and analyzed the product selection mechanism.}
}

@article{Muntjir2016,
title = {An Enhanced Framework with Advanced Study to Incorporate the Searching of E-Commerce Products Using Modernization of Database Queries},
journal = {International Journal of Advanced Computer Science and Applications},
doi = {10.14569/IJACSA.2016.070514},
url = {http://dx.doi.org/10.14569/IJACSA.2016.070514},
year = {2016},
publisher = {The Science and Information Organization},
volume = {7},
number = {5},
author = {Mohd Muntjir and Ahmad Tasnim Siddiqui}
}