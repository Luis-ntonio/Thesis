According to He et al. \cite{he2023survey} and Reddy \cite{REDDY2023101304}, Large Language Models (LLMs) such as GPT-4, BERT, LLama, and LLama2 are transforming sectors like healthcare. Furthermore, Varshney \cite{Varshney_2024} highlights their significant impact on finance and e-commerce by their remarkable ability to understand and generate text that closely resembles human communication. These models play a pivotal role in enhancing decision-making processes, automating customer service, and improving data analysis.
\\\\
Although these models perform well across various applications, according to Bergmann \cite{Bergmann_2024}, there are scenarios where they require specific training to handle particular tasks effectively. Fine-tuning is a strategic approach to enhance model performance by training pre-existing models with specialized datasets to better meet domain-specific needs. Examples of such specialized applications include LLama2-chat by Touvron et al. \cite{touvron2023llama}, Mistral Instruct by Jiang et al. \cite{jiang2023mistral}, and StructLM by Zhuang et al. \cite{zhuang2024structlm}, each tailored with unique datasets. However, the lack of high-quality, focused datasets, particularly in areas like product attributes and e-commerce, remains a significant challenge, emphasizing the need for comprehensive datasets that enable models to interact effectively with detailed product information.
\\\\
Creating a dataset involves a deep understanding of the data types collected. While Audio and Video are significant, Text and Tabular data are more common in real-world applications, appearing in formats such as Excel tables, Wikipedia pages, and other spreadsheets. These data can be formatted in several styles, including HTML, CSV (Comma Separated Values), TSV (Tab Separated Values), Markdown, DFLoader, Data-Matrix, and JSON. JSON, in particular, is highly valued for its readability and easy integration with contemporary web technologies \cite{singha2023tabular}.
\\\\
According to Gao et al. \cite{gao2024jsontuning}, using JSON-centric methods to fine-tune models significantly enhances their capacity to process and generate structured data accurately. This capability is crucial for e-commerce platforms, where product data's structure and content frequently vary. By focusing on JSON-structured data to fine-tune LLMs like LLama2-chat, Mistral Instruct, and StructLM, this project seeks to significantly refine the extraction and normalization of product specifications. This will lead to more accurate and contextually relevant product reviews, directly improving them and making them more humanized.
